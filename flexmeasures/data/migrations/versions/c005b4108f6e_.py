"""empty message

Revision ID: c005b4108f6e
Revises: 40d6c8e4be94
Create Date: 2023-10-12 15:26:05.782244

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision = "c005b4108f6e"
down_revision = "40d6c8e4be94"
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table("asset_type", schema=None) as batch_op:
        batch_op.drop_index("asset_type_can_curtail_idx")
        batch_op.drop_index("asset_type_can_shift_idx")

    op.drop_table("asset_type")
    op.drop_table("market_type")
    op.drop_table("asset")
    op.drop_table("weather_sensor_type")
    with op.batch_alter_table("power", schema=None) as batch_op:
        batch_op.drop_index("power_datetime_idx")
        batch_op.drop_index("power_sensor_id_idx")

    op.drop_table("power")
    op.drop_table("market")
    op.drop_table("weather_sensor")
    with op.batch_alter_table("price", schema=None) as batch_op:
        batch_op.drop_index("price_datetime_idx")
        batch_op.drop_index("price_sensor_id_idx")

    op.drop_table("price")
    with op.batch_alter_table("weather", schema=None) as batch_op:
        batch_op.drop_index("weather_datetime_idx")
        batch_op.drop_index("weather_sensor_id_idx")

    op.drop_table("weather")
    with op.batch_alter_table("account", schema=None) as batch_op:
        batch_op.add_column(
            sa.Column("consultancy_account_id", sa.Integer(), nullable=True)
        )
        batch_op.create_foreign_key(
            batch_op.f("account_consultancy_account_id_account_fkey"),
            "account",
            ["consultancy_account_id"],
            ["id"],
        )

    with op.batch_alter_table("annotation", schema=None) as batch_op:
        batch_op.alter_column("source_id", existing_type=sa.INTEGER(), nullable=True)
        batch_op.alter_column(
            "type",
            existing_type=postgresql.ENUM(
                "alert", "holiday", "label", "feedback", name="annotation_type"
            ),
            nullable=True,
        )

    with op.batch_alter_table("data_source", schema=None) as batch_op:
        batch_op.alter_column(
            "name",
            existing_type=sa.VARCHAR(length=80),
            type_=sa.String(length=120),
            existing_nullable=False,
        )
        batch_op.alter_column(
            "attributes",
            existing_type=postgresql.JSON(astext_type=sa.Text()),
            nullable=False,
        )

    with op.batch_alter_table("timed_belief", schema=None) as batch_op:
        batch_op.drop_constraint(
            "timed_belief_source_id_source_fkey", type_="foreignkey"
        )
        batch_op.create_foreign_key(
            batch_op.f("timed_belief_source_id_data_source_fkey"),
            "data_source",
            ["source_id"],
            ["id"],
        )

    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table("timed_belief", schema=None) as batch_op:
        batch_op.drop_constraint(
            batch_op.f("timed_belief_source_id_data_source_fkey"), type_="foreignkey"
        )
        batch_op.create_foreign_key(
            "timed_belief_source_id_source_fkey",
            "data_source",
            ["source_id"],
            ["id"],
            ondelete="CASCADE",
        )

    with op.batch_alter_table("data_source", schema=None) as batch_op:
        batch_op.alter_column(
            "attributes",
            existing_type=postgresql.JSON(astext_type=sa.Text()),
            nullable=True,
        )
        batch_op.alter_column(
            "name",
            existing_type=sa.String(length=120),
            type_=sa.VARCHAR(length=80),
            existing_nullable=False,
        )

    with op.batch_alter_table("annotation", schema=None) as batch_op:
        batch_op.alter_column(
            "type",
            existing_type=postgresql.ENUM(
                "alert", "holiday", "label", "feedback", name="annotation_type"
            ),
            nullable=False,
        )
        batch_op.alter_column("source_id", existing_type=sa.INTEGER(), nullable=False)

    with op.batch_alter_table("account", schema=None) as batch_op:
        batch_op.drop_constraint(
            batch_op.f("account_consultancy_account_id_account_fkey"),
            type_="foreignkey",
        )
        batch_op.drop_column("consultancy_account_id")

    op.create_table(
        "weather",
        sa.Column("sensor_id", sa.INTEGER(), autoincrement=False, nullable=False),
        sa.Column(
            "datetime",
            postgresql.TIMESTAMP(timezone=True),
            autoincrement=False,
            nullable=False,
        ),
        sa.Column(
            "value",
            postgresql.DOUBLE_PRECISION(precision=53),
            autoincrement=False,
            nullable=False,
        ),
        sa.Column(
            "horizon", postgresql.INTERVAL(), autoincrement=False, nullable=False
        ),
        sa.Column("data_source_id", sa.INTEGER(), autoincrement=False, nullable=False),
        sa.ForeignKeyConstraint(
            ["data_source_id"],
            ["data_source.id"],
            name="weather_data_source_data_sources_fkey",
        ),
        sa.ForeignKeyConstraint(
            ["sensor_id"], ["sensor.id"], name="weather_sensor_id_sensor_fkey"
        ),
        sa.PrimaryKeyConstraint(
            "datetime", "sensor_id", "horizon", "data_source_id", name="weather_pkey"
        ),
    )
    with op.batch_alter_table("weather", schema=None) as batch_op:
        batch_op.create_index("weather_sensor_id_idx", ["sensor_id"], unique=False)
        batch_op.create_index("weather_datetime_idx", ["datetime"], unique=False)

    op.create_table(
        "price",
        sa.Column(
            "datetime",
            postgresql.TIMESTAMP(timezone=True),
            autoincrement=False,
            nullable=False,
        ),
        sa.Column("sensor_id", sa.INTEGER(), autoincrement=False, nullable=False),
        sa.Column(
            "value",
            postgresql.DOUBLE_PRECISION(precision=53),
            autoincrement=False,
            nullable=False,
        ),
        sa.Column(
            "horizon", postgresql.INTERVAL(), autoincrement=False, nullable=False
        ),
        sa.Column("data_source_id", sa.INTEGER(), autoincrement=False, nullable=False),
        sa.ForeignKeyConstraint(
            ["data_source_id"],
            ["data_source.id"],
            name="price_data_source_data_sources_fkey",
        ),
        sa.ForeignKeyConstraint(
            ["sensor_id"], ["sensor.id"], name="price_sensor_id_sensor_fkey"
        ),
        sa.PrimaryKeyConstraint(
            "datetime", "sensor_id", "horizon", "data_source_id", name="price_pkey"
        ),
    )
    with op.batch_alter_table("price", schema=None) as batch_op:
        batch_op.create_index("price_sensor_id_idx", ["sensor_id"], unique=False)
        batch_op.create_index("price_datetime_idx", ["datetime"], unique=False)

    op.create_table(
        "weather_sensor",
        sa.Column("id", sa.INTEGER(), autoincrement=True, nullable=False),
        sa.Column("name", sa.VARCHAR(length=80), autoincrement=False, nullable=True),
        sa.Column(
            "weather_sensor_type_name",
            sa.VARCHAR(length=80),
            autoincrement=False,
            nullable=False,
        ),
        sa.Column(
            "latitude",
            postgresql.DOUBLE_PRECISION(precision=53),
            autoincrement=False,
            nullable=False,
        ),
        sa.Column(
            "longitude",
            postgresql.DOUBLE_PRECISION(precision=53),
            autoincrement=False,
            nullable=False,
        ),
        sa.Column(
            "unit",
            sa.VARCHAR(length=80),
            server_default=sa.text("''::character varying"),
            autoincrement=False,
            nullable=False,
        ),
        sa.Column(
            "display_name",
            sa.VARCHAR(length=80),
            server_default=sa.text("''::character varying"),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column(
            "event_resolution",
            postgresql.INTERVAL(),
            server_default=sa.text("'00:00:00'::interval"),
            autoincrement=False,
            nullable=False,
        ),
        sa.Column(
            "knowledge_horizon_fnc",
            sa.VARCHAR(length=80),
            autoincrement=False,
            nullable=False,
        ),
        sa.Column(
            "knowledge_horizon_par",
            postgresql.JSON(astext_type=sa.Text()),
            autoincrement=False,
            nullable=False,
        ),
        sa.Column(
            "timezone", sa.VARCHAR(length=80), autoincrement=False, nullable=False
        ),
        sa.ForeignKeyConstraint(
            ["id"], ["sensor.id"], name="weather_sensor_id_sensor_fkey"
        ),
        sa.ForeignKeyConstraint(
            ["weather_sensor_type_name"],
            ["weather_sensor_type.name"],
            name="weather_sensor_weather_sensor_type_name_weather_sensor__1390",
        ),
        sa.PrimaryKeyConstraint("id", name="weather_sensor_pkey"),
        sa.UniqueConstraint("name", name="weather_sensor_name_key"),
        sa.UniqueConstraint(
            "weather_sensor_type_name",
            "latitude",
            "longitude",
            name="weather_sensor_type_name_latitude_longitude_key",
        ),
    )
    op.create_table(
        "market",
        sa.Column(
            "id",
            sa.INTEGER(),
            server_default=sa.text("nextval('market_id_seq'::regclass)"),
            autoincrement=True,
            nullable=False,
        ),
        sa.Column("name", sa.VARCHAR(length=80), autoincrement=False, nullable=True),
        sa.Column(
            "market_type_name",
            sa.VARCHAR(length=80),
            autoincrement=False,
            nullable=False,
        ),
        sa.Column(
            "display_name",
            sa.VARCHAR(length=80),
            server_default=sa.text("''::character varying"),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column(
            "unit",
            sa.VARCHAR(length=80),
            server_default=sa.text("''::character varying"),
            autoincrement=False,
            nullable=False,
        ),
        sa.Column(
            "event_resolution",
            postgresql.INTERVAL(),
            server_default=sa.text("'00:00:00'::interval"),
            autoincrement=False,
            nullable=False,
        ),
        sa.Column(
            "knowledge_horizon_fnc",
            sa.VARCHAR(length=80),
            autoincrement=False,
            nullable=False,
        ),
        sa.Column(
            "knowledge_horizon_par",
            postgresql.JSON(astext_type=sa.Text()),
            autoincrement=False,
            nullable=False,
        ),
        sa.Column(
            "timezone", sa.VARCHAR(length=80), autoincrement=False, nullable=False
        ),
        sa.ForeignKeyConstraint(["id"], ["sensor.id"], name="market_id_sensor_fkey"),
        sa.ForeignKeyConstraint(
            ["market_type_name"],
            ["market_type.name"],
            name="market_market_type_name_market_type_fkey",
        ),
        sa.PrimaryKeyConstraint("id", name="market_pkey"),
        sa.UniqueConstraint("display_name", name="market_display_name_key"),
        sa.UniqueConstraint("name", name="market_name_key"),
        postgresql_ignore_search_path=False,
    )
    op.create_table(
        "power",
        sa.Column(
            "datetime",
            postgresql.TIMESTAMP(timezone=True),
            autoincrement=False,
            nullable=False,
        ),
        sa.Column("sensor_id", sa.INTEGER(), autoincrement=False, nullable=False),
        sa.Column(
            "value",
            postgresql.DOUBLE_PRECISION(precision=53),
            autoincrement=False,
            nullable=False,
        ),
        sa.Column(
            "horizon", postgresql.INTERVAL(), autoincrement=False, nullable=False
        ),
        sa.Column("data_source_id", sa.INTEGER(), autoincrement=False, nullable=False),
        sa.ForeignKeyConstraint(
            ["data_source_id"],
            ["data_source.id"],
            name="power_data_source_data_sources_fkey",
        ),
        sa.ForeignKeyConstraint(
            ["sensor_id"],
            ["sensor.id"],
            name="power_sensor_id_sensor_fkey",
            ondelete="CASCADE",
        ),
        sa.PrimaryKeyConstraint(
            "datetime", "sensor_id", "horizon", "data_source_id", name="power_pkey"
        ),
    )
    with op.batch_alter_table("power", schema=None) as batch_op:
        batch_op.create_index("power_sensor_id_idx", ["sensor_id"], unique=False)
        batch_op.create_index("power_datetime_idx", ["datetime"], unique=False)

    op.create_table(
        "weather_sensor_type",
        sa.Column("name", sa.VARCHAR(length=80), autoincrement=False, nullable=False),
        sa.Column(
            "display_name",
            sa.VARCHAR(length=80),
            server_default=sa.text("''::character varying"),
            autoincrement=False,
            nullable=True,
        ),
        sa.PrimaryKeyConstraint("name", name="weather_sensor_type_pkey"),
        sa.UniqueConstraint(
            "display_name", name="weather_sensor_type_display_name_key"
        ),
    )
    op.create_table(
        "asset",
        sa.Column("id", sa.INTEGER(), autoincrement=True, nullable=False),
        sa.Column(
            "asset_type_name",
            sa.VARCHAR(length=80),
            autoincrement=False,
            nullable=False,
        ),
        sa.Column("name", sa.VARCHAR(length=80), autoincrement=False, nullable=True),
        sa.Column(
            "display_name", sa.VARCHAR(length=80), autoincrement=False, nullable=True
        ),
        sa.Column(
            "capacity_in_mw",
            postgresql.DOUBLE_PRECISION(precision=53),
            autoincrement=False,
            nullable=False,
        ),
        sa.Column(
            "latitude",
            postgresql.DOUBLE_PRECISION(precision=53),
            autoincrement=False,
            nullable=False,
        ),
        sa.Column(
            "longitude",
            postgresql.DOUBLE_PRECISION(precision=53),
            autoincrement=False,
            nullable=False,
        ),
        sa.Column("owner_id", sa.INTEGER(), autoincrement=False, nullable=True),
        sa.Column(
            "min_soc_in_mwh",
            postgresql.DOUBLE_PRECISION(precision=53),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column(
            "max_soc_in_mwh",
            postgresql.DOUBLE_PRECISION(precision=53),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column(
            "soc_in_mwh",
            postgresql.DOUBLE_PRECISION(precision=53),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column(
            "soc_datetime",
            postgresql.TIMESTAMP(timezone=True),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column("soc_udi_event_id", sa.INTEGER(), autoincrement=False, nullable=True),
        sa.Column(
            "unit",
            sa.VARCHAR(length=80),
            server_default=sa.text("''::character varying"),
            autoincrement=False,
            nullable=False,
        ),
        sa.Column("market_id", sa.INTEGER(), autoincrement=False, nullable=True),
        sa.Column(
            "event_resolution",
            postgresql.INTERVAL(),
            server_default=sa.text("'00:00:00'::interval"),
            autoincrement=False,
            nullable=False,
        ),
        sa.Column(
            "knowledge_horizon_fnc",
            sa.VARCHAR(length=80),
            autoincrement=False,
            nullable=False,
        ),
        sa.Column(
            "knowledge_horizon_par",
            postgresql.JSON(astext_type=sa.Text()),
            autoincrement=False,
            nullable=False,
        ),
        sa.Column(
            "timezone", sa.VARCHAR(length=80), autoincrement=False, nullable=False
        ),
        sa.ForeignKeyConstraint(
            ["asset_type_name"],
            ["asset_type.name"],
            name="asset_asset_type_name_asset_type_fkey",
        ),
        sa.ForeignKeyConstraint(
            ["id"], ["sensor.id"], name="asset_id_sensor_fkey", ondelete="CASCADE"
        ),
        sa.ForeignKeyConstraint(
            ["market_id"], ["market.id"], name="asset_market_id_market_fkey"
        ),
        sa.ForeignKeyConstraint(
            ["owner_id"],
            ["fm_user.id"],
            name="asset_owner_id_bvp_users_fkey",
            ondelete="CASCADE",
        ),
        sa.PrimaryKeyConstraint("id", name="asset_pkey"),
        sa.UniqueConstraint("display_name", name="asset_display_name_key"),
        sa.UniqueConstraint("name", name="asset_name_key"),
    )
    op.create_table(
        "market_type",
        sa.Column("name", sa.VARCHAR(length=80), autoincrement=False, nullable=False),
        sa.Column(
            "daily_seasonality", sa.BOOLEAN(), autoincrement=False, nullable=False
        ),
        sa.Column(
            "weekly_seasonality", sa.BOOLEAN(), autoincrement=False, nullable=False
        ),
        sa.Column(
            "yearly_seasonality", sa.BOOLEAN(), autoincrement=False, nullable=False
        ),
        sa.Column(
            "display_name",
            sa.VARCHAR(length=80),
            server_default=sa.text("''::character varying"),
            autoincrement=False,
            nullable=True,
        ),
        sa.PrimaryKeyConstraint("name", name="market_type_pkey"),
        sa.UniqueConstraint("display_name", name="market_type_display_name_key"),
    )
    op.create_table(
        "asset_type",
        sa.Column("name", sa.VARCHAR(length=80), autoincrement=False, nullable=False),
        sa.Column("is_consumer", sa.BOOLEAN(), autoincrement=False, nullable=False),
        sa.Column("is_producer", sa.BOOLEAN(), autoincrement=False, nullable=False),
        sa.Column("can_curtail", sa.BOOLEAN(), autoincrement=False, nullable=False),
        sa.Column("can_shift", sa.BOOLEAN(), autoincrement=False, nullable=False),
        sa.Column(
            "daily_seasonality", sa.BOOLEAN(), autoincrement=False, nullable=False
        ),
        sa.Column(
            "weekly_seasonality", sa.BOOLEAN(), autoincrement=False, nullable=False
        ),
        sa.Column(
            "yearly_seasonality", sa.BOOLEAN(), autoincrement=False, nullable=False
        ),
        sa.Column(
            "display_name",
            sa.VARCHAR(length=80),
            server_default=sa.text("''::character varying"),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column(
            "hover_label", sa.VARCHAR(length=80), autoincrement=False, nullable=True
        ),
        sa.PrimaryKeyConstraint("name", name="asset_type_pkey"),
        sa.UniqueConstraint("display_name", name="asset_type_display_name_key"),
    )
    with op.batch_alter_table("asset_type", schema=None) as batch_op:
        batch_op.create_index("asset_type_can_shift_idx", ["can_shift"], unique=False)
        batch_op.create_index(
            "asset_type_can_curtail_idx", ["can_curtail"], unique=False
        )

    # ### end Alembic commands ###
